{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2f28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "X_PATH = \"../processed/preprocessed_X_seq.npy\"\n",
    "Y_PATH = \"../processed/preprocessed_y_seq.npy\"\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016e0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq: (78773, 32, 52)\n",
      "y_seq: (78773, 32)\n"
     ]
    }
   ],
   "source": [
    "X_seq = np.load(X_PATH)  # shape: (N_windows, 32, 52)\n",
    "y_seq = np.load(Y_PATH)  # shape: (N_windows, 32)\n",
    "\n",
    "print(\"X_seq:\", X_seq.shape)\n",
    "print(\"y_seq:\", y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c6e25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_window shape: (78773,)\n",
      "Window label distribution: {np.int64(0): np.int64(56230), np.int64(1): np.int64(22543)}\n",
      "X_flat shape: (78773, 1664)\n"
     ]
    }
   ],
   "source": [
    "# Window-level label: 1 if any flow in window is attack, else 0\n",
    "y_window = (y_seq.max(axis=1) > 0).astype(int)   # shape: (N_windows,)\n",
    "\n",
    "print(\"y_window shape:\", y_window.shape)\n",
    "unique, counts = np.unique(y_window, return_counts=True)\n",
    "print(\"Window label distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "# Flatten each window: (32, 52) -> (1664,) for tabular models\n",
    "N, L, F = X_seq.shape\n",
    "X_flat = X_seq.reshape(N, L * F)\n",
    "print(\"X_flat shape:\", X_flat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be9b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (55141, 1664) (55141,)\n",
      "Val  : (11815, 1664) (11815,)\n",
      "Test : (11817, 1664) (11817,)\n"
     ]
    }
   ],
   "source": [
    "def split_window_data(X_flat, y_win, train_ratio=0.7, val_ratio=0.15):\n",
    "    N = X_flat.shape[0]\n",
    "    n_train = int(N * train_ratio)\n",
    "    n_val = int(N * val_ratio)\n",
    "    \n",
    "    X_train = X_flat[:n_train]\n",
    "    y_train = y_win[:n_train]\n",
    "    X_val   = X_flat[n_train:n_train+n_val]\n",
    "    y_val   = y_win[n_train:n_train+n_val]\n",
    "    X_test  = X_flat[n_train+n_val:]\n",
    "    y_test  = y_win[n_train+n_val:]\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = split_window_data(X_flat, y_window)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val  :\", X_val.shape, y_val.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc1ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [43271. 11870.] -> class weights: [0.63715884 2.3227043 ]\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_pred, model_name=\"Model\"):\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"üîç {model_name} Metrics:\")\n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall   :\", rec)\n",
    "    print(\"F1-score :\", f1)\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# Class weights for supervised models (to help recall)\n",
    "counts = np.bincount(y_train, minlength=2).astype(float)\n",
    "weights = counts.sum() / (2 * counts + 1e-8)\n",
    "print(\"Class counts:\", counts, \"-> class weights:\", weights)\n",
    "class_weights_np = weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d0ec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç XGBoost Metrics:\n",
      "Accuracy : 0.5367690615215368\n",
      "Precision: 0.9906976744186047\n",
      "Recall   : 0.03746701846965699\n",
      "F1-score : 0.07220338983050847\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.536769</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0.037467</td>\n",
       "      <td>0.072203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy  Precision    Recall        F1\n",
       "0  XGBoost  0.536769   0.990698  0.037467  0.072203"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "acc_xgb, prec_xgb, rec_xgb, f1_xgb = compute_metrics(y_test, y_pred_xgb, \"XGBoost\")\n",
    "\n",
    "df_xgb = pd.DataFrame([[ \"XGBoost\", acc_xgb, prec_xgb, rec_xgb, f1_xgb ]],\n",
    "                      columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_xgb.to_csv(\"results/XGBoost.csv\", index=False)\n",
    "df_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c974c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11870, number of negative: 43271\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.552818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 377400\n",
      "[LightGBM] [Info] Number of data points in the train set: 55141, number of used features: 1664\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.215266 -> initscore=-1.293468\n",
      "[LightGBM] [Info] Start training from score -1.293468\n",
      "üîç LightGBM Metrics:\n",
      "Accuracy : 0.5981213505965981\n",
      "Precision: 0.9989339019189766\n",
      "Recall   : 0.1648197009674582\n",
      "F1-score : 0.2829533444058584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\ids\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.598121</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.16482</td>\n",
       "      <td>0.282953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision   Recall        F1\n",
       "0  LightGBM  0.598121   0.998934  0.16482  0.282953"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgbm.predict(X_test)\n",
    "acc_lgb, prec_lgb, rec_lgb, f1_lgb = compute_metrics(y_test, y_pred_lgb, \"LightGBM\")\n",
    "\n",
    "df_lgb = pd.DataFrame([[ \"LightGBM\", acc_lgb, prec_lgb, rec_lgb, f1_lgb ]],\n",
    "                      columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_lgb.to_csv(\"results/LightGBM.csv\", index=False)\n",
    "df_lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f25566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds_mlp = WindowDataset(X_train, y_train)\n",
    "val_ds_mlp   = WindowDataset(X_val, y_val)\n",
    "test_ds_mlp  = WindowDataset(X_test, y_test)\n",
    "\n",
    "train_loader_mlp = DataLoader(train_ds_mlp, batch_size=256, shuffle=True)\n",
    "val_loader_mlp   = DataLoader(val_ds_mlp,   batch_size=256, shuffle=False)\n",
    "test_loader_mlp  = DataLoader(test_ds_mlp,  batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfb6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_IDS(nn.Module):\n",
    "    def __init__(self, in_dim, hidden1=512, hidden2=256, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden2, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "mlp_model = MLP_IDS(in_dim=X_train.shape[1]).to(DEVICE)\n",
    "class_weights_t = torch.tensor(class_weights_np, dtype=torch.float32, device=DEVICE)\n",
    "criterion_mlp = nn.CrossEntropyLoss(weight=class_weights_t)\n",
    "optimizer_mlp = torch.optim.Adam(mlp_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5ce9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ MLP best model saved at epoch 1 | Val Acc=0.8461\n",
      "Epoch 1/10 | Train Loss=0.4160 Acc=0.8786 | Val Loss=0.7201 Acc=0.8461\n",
      "Epoch 2/10 | Train Loss=0.3771 Acc=0.8870 | Val Loss=1.1650 Acc=0.7438\n",
      "Epoch 3/10 | Train Loss=0.3473 Acc=0.8869 | Val Loss=0.8631 Acc=0.8099\n",
      "Epoch 4/10 | Train Loss=0.3103 Acc=0.8877 | Val Loss=1.6025 Acc=0.6923\n",
      "Epoch 5/10 | Train Loss=0.2711 Acc=0.9012 | Val Loss=0.9927 Acc=0.8243\n",
      "Epoch 6/10 | Train Loss=0.2253 Acc=0.9177 | Val Loss=1.6839 Acc=0.7997\n",
      "Epoch 7/10 | Train Loss=0.1899 Acc=0.9306 | Val Loss=1.5869 Acc=0.8115\n",
      "Epoch 8/10 | Train Loss=0.1570 Acc=0.9439 | Val Loss=1.5945 Acc=0.8208\n",
      "Epoch 9/10 | Train Loss=0.1341 Acc=0.9524 | Val Loss=2.2657 Acc=0.8002\n",
      "Epoch 10/10 | Train Loss=0.1145 Acc=0.9588 | Val Loss=2.0525 Acc=0.8154\n",
      "MLP training done.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_MLP = 10\n",
    "best_val_acc_mlp = -1\n",
    "best_model_mlp_path = \"results/mlp_best.pth\"\n",
    "\n",
    "def acc_batch(logits, y):\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    return (preds == y).float().mean().item()\n",
    "\n",
    "for epoch in range(1, EPOCHS_MLP+1):\n",
    "    mlp_model.train()\n",
    "    tl, ta = 0, 0\n",
    "    for xb, yb in train_loader_mlp:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = mlp_model(xb)\n",
    "        loss = criterion_mlp(logits, yb)\n",
    "        optimizer_mlp.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_mlp.step()\n",
    "        tl += loss.item()\n",
    "        ta += acc_batch(logits, yb)\n",
    "    tl /= len(train_loader_mlp); ta /= len(train_loader_mlp)\n",
    "\n",
    "    mlp_model.eval()\n",
    "    vl, va = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader_mlp:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = mlp_model(xb)\n",
    "            loss = criterion_mlp(logits, yb)\n",
    "            vl += loss.item()\n",
    "            va += acc_batch(logits, yb)\n",
    "    vl /= len(val_loader_mlp); va /= len(val_loader_mlp)\n",
    "\n",
    "    if va > best_val_acc_mlp:\n",
    "        best_val_acc_mlp = va\n",
    "        torch.save(mlp_model.state_dict(), best_model_mlp_path)\n",
    "        print(f\"üíæ MLP best model saved at epoch {epoch} | Val Acc={va:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS_MLP} | Train Loss={tl:.4f} Acc={ta:.4f} | Val Loss={vl:.4f} Acc={va:.4f}\")\n",
    "\n",
    "print(\"MLP training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3383306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MLP Metrics:\n",
      "Accuracy : 0.6026064144876027\n",
      "Precision: 0.914501257334451\n",
      "Recall   : 0.1919085312225154\n",
      "F1-score : 0.3172433847048561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.602606</td>\n",
       "      <td>0.914501</td>\n",
       "      <td>0.191909</td>\n",
       "      <td>0.317243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Precision    Recall        F1\n",
       "0   MLP  0.602606   0.914501  0.191909  0.317243"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.load_state_dict(torch.load(best_model_mlp_path))\n",
    "mlp_model.eval()\n",
    "\n",
    "y_true_mlp, y_pred_mlp = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader_mlp:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = mlp_model(xb)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        y_true_mlp.extend(yb.numpy().tolist())\n",
    "        y_pred_mlp.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "acc_mlp, prec_mlp, rec_mlp, f1_mlp = compute_metrics(y_true_mlp, y_pred_mlp, \"MLP\")\n",
    "\n",
    "df_mlp = pd.DataFrame([[ \"MLP\", acc_mlp, prec_mlp, rec_mlp, f1_mlp ]],\n",
    "                      columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_mlp.to_csv(\"results/MLP.csv\", index=False)\n",
    "df_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c637a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_mean shape: (78773, 52)\n",
      "Train (mean): (55141, 52) (55141,)\n",
      "Val   (mean): (11815, 52) (11815,)\n",
      "Test  (mean): (11817, 52) (11817,)\n"
     ]
    }
   ],
   "source": [
    "# Mean-pool across the 32 timesteps -> (N, 52)\n",
    "X_mean = X_seq.mean(axis=1)   # (N, 52)\n",
    "print(\"X_mean shape:\", X_mean.shape)\n",
    "\n",
    "(X_train_m, y_train_m), (X_val_m, y_val_m), (X_test_m, y_test_m) = split_window_data(X_mean, y_window)\n",
    "\n",
    "print(\"Train (mean):\", X_train_m.shape, y_train_m.shape)\n",
    "print(\"Val   (mean):\", X_val_m.shape, y_val_m.shape)\n",
    "print(\"Test  (mean):\", X_test_m.shape, y_test_m.shape)\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].unsqueeze(0)  # (1, 52) -> sequence length 1\n",
    "        return x, self.y[idx]\n",
    "\n",
    "train_loader_lstm = DataLoader(LSTMDataset(X_train_m, y_train_m), batch_size=256, shuffle=True)\n",
    "val_loader_lstm   = DataLoader(LSTMDataset(X_val_m, y_val_m),   batch_size=256, shuffle=False)\n",
    "test_loader_lstm  = DataLoader(LSTMDataset(X_test_m, y_test_m), batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e3feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_IDS(nn.Module):\n",
    "    def __init__(self, feature_dim=52, hidden_dim=128, num_layers=1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=feature_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 52)\n",
    "        out, _ = self.lstm(x)        # (B, 1, hidden_dim)\n",
    "        last = out[:, -1, :]         # (B, hidden_dim)\n",
    "        return self.fc(last)\n",
    "\n",
    "lstm_model = LSTM_IDS(feature_dim=X_train_m.shape[1]).to(DEVICE)\n",
    "criterion_lstm = nn.CrossEntropyLoss(weight=class_weights_t)\n",
    "optimizer_lstm = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a23bed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ LSTM best model saved at epoch 1 | Val Acc=0.7952\n",
      "Epoch 1/10 | Train Loss=0.4680 Acc=0.8599 | Val Loss=0.6721 Acc=0.7952\n",
      "üíæ LSTM best model saved at epoch 2 | Val Acc=0.8085\n",
      "Epoch 2/10 | Train Loss=0.4040 Acc=0.8770 | Val Loss=0.7226 Acc=0.8085\n",
      "Epoch 3/10 | Train Loss=0.3923 Acc=0.8834 | Val Loss=0.8138 Acc=0.7991\n",
      "üíæ LSTM best model saved at epoch 4 | Val Acc=0.8086\n",
      "Epoch 4/10 | Train Loss=0.3841 Acc=0.8853 | Val Loss=0.8333 Acc=0.8086\n",
      "Epoch 5/10 | Train Loss=0.3777 Acc=0.8864 | Val Loss=0.9105 Acc=0.8007\n",
      "Epoch 6/10 | Train Loss=0.3715 Acc=0.8873 | Val Loss=0.9317 Acc=0.7998\n",
      "Epoch 7/10 | Train Loss=0.3666 Acc=0.8870 | Val Loss=0.9275 Acc=0.8071\n",
      "Epoch 8/10 | Train Loss=0.3626 Acc=0.8875 | Val Loss=1.0106 Acc=0.8017\n",
      "Epoch 9/10 | Train Loss=0.3585 Acc=0.8881 | Val Loss=1.0109 Acc=0.8016\n",
      "Epoch 10/10 | Train Loss=0.3552 Acc=0.8876 | Val Loss=1.0288 Acc=0.7935\n",
      "LSTM training done.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_LSTM = 10\n",
    "best_val_acc_lstm = -1\n",
    "best_model_lstm_path = \"results/lstm_best.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS_LSTM+1):\n",
    "    lstm_model.train()\n",
    "    tl, ta = 0, 0\n",
    "    for xb, yb in train_loader_lstm:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = lstm_model(xb)\n",
    "        loss = criterion_lstm(logits, yb)\n",
    "        optimizer_lstm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "        tl += loss.item()\n",
    "        ta += acc_batch(logits, yb)\n",
    "    tl /= len(train_loader_lstm); ta /= len(train_loader_lstm)\n",
    "\n",
    "    lstm_model.eval()\n",
    "    vl, va = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader_lstm:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = lstm_model(xb)\n",
    "            loss = criterion_lstm(logits, yb)\n",
    "            vl += loss.item()\n",
    "            va += acc_batch(logits, yb)\n",
    "    vl /= len(val_loader_lstm); va /= len(val_loader_lstm)\n",
    "\n",
    "    if va > best_val_acc_lstm:\n",
    "        best_val_acc_lstm = va\n",
    "        torch.save(lstm_model.state_dict(), best_model_lstm_path)\n",
    "        print(f\"üíæ LSTM best model saved at epoch {epoch} | Val Acc={va:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS_LSTM} | Train Loss={tl:.4f} Acc={ta:.4f} | Val Loss={vl:.4f} Acc={va:.4f}\")\n",
    "\n",
    "print(\"LSTM training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6baaffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç LSTM Metrics:\n",
      "Accuracy : 0.592959295929593\n",
      "Precision: 0.7501429388221841\n",
      "Recall   : 0.23078276165347406\n",
      "F1-score : 0.35297282754909876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.592959</td>\n",
       "      <td>0.750143</td>\n",
       "      <td>0.230783</td>\n",
       "      <td>0.352973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Precision    Recall        F1\n",
       "0  LSTM  0.592959   0.750143  0.230783  0.352973"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.load_state_dict(torch.load(best_model_lstm_path))\n",
    "lstm_model.eval()\n",
    "\n",
    "y_true_lstm, y_pred_lstm = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader_lstm:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = lstm_model(xb)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        y_true_lstm.extend(yb.numpy().tolist())\n",
    "        y_pred_lstm.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "acc_lstm, prec_lstm, rec_lstm, f1_lstm = compute_metrics(y_true_lstm, y_pred_lstm, \"LSTM\")\n",
    "\n",
    "df_lstm = pd.DataFrame([[ \"LSTM\", acc_lstm, prec_lstm, rec_lstm, f1_lstm ]],\n",
    "                       columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_lstm.to_csv(\"results/LSTM.csv\", index=False)\n",
    "df_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e7322a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal windows for IsolationForest training: 43271\n",
      "üîç IsolationForest Metrics:\n",
      "Accuracy : 0.5335533553355336\n",
      "Precision: 0.546430488459474\n",
      "Recall   : 0.17906772207563765\n",
      "F1-score : 0.269740328563858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.533553</td>\n",
       "      <td>0.54643</td>\n",
       "      <td>0.179068</td>\n",
       "      <td>0.26974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision    Recall       F1\n",
       "0  IsolationForest  0.533553    0.54643  0.179068  0.26974"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train only on NORMAL windows (y_train == 0)\n",
    "X_train_norm = X_train[y_train == 0]\n",
    "\n",
    "print(\"Normal windows for IsolationForest training:\", X_train_norm.shape[0])\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.1,   # rough guess, can tune\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "iso.fit(X_train_norm)\n",
    "\n",
    "# Predict: -1 = anomaly, 1 = normal\n",
    "pred_if = iso.predict(X_test)\n",
    "y_pred_if = (pred_if == -1).astype(int)  # 1 = attack\n",
    "\n",
    "acc_if, prec_if, rec_if, f1_if = compute_metrics(y_test, y_pred_if, \"IsolationForest\")\n",
    "\n",
    "df_if = pd.DataFrame([[ \"IsolationForest\", acc_if, prec_if, rec_if, f1_if ]],\n",
    "                     columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_if.to_csv(\"results/IsolationForest.csv\", index=False)\n",
    "df_if\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5db02cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_IDS(nn.Module):\n",
    "    def __init__(self, in_dim, hidden1=512, hidden2=256):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden2, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1, in_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "        return recon\n",
    "\n",
    "# Train AE on normal windows only (train split)\n",
    "X_train_norm_ae = X_train[y_train == 0]\n",
    "train_ds_ae = WindowDataset(X_train_norm_ae, np.zeros(len(X_train_norm_ae)))\n",
    "train_loader_ae = DataLoader(train_ds_ae, batch_size=256, shuffle=True)\n",
    "\n",
    "ae_model = AE_IDS(in_dim=X_train.shape[1]).to(DEVICE)\n",
    "criterion_ae = nn.MSELoss()\n",
    "optimizer_ae = torch.optim.Adam(ae_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c95d65ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Recon Loss=0.565026\n",
      "Epoch 2/10 | Recon Loss=0.424239\n",
      "Epoch 3/10 | Recon Loss=0.402436\n",
      "Epoch 4/10 | Recon Loss=0.388899\n",
      "Epoch 5/10 | Recon Loss=0.373739\n",
      "Epoch 6/10 | Recon Loss=0.571275\n",
      "Epoch 7/10 | Recon Loss=0.502089\n",
      "Epoch 8/10 | Recon Loss=0.437249\n",
      "Epoch 9/10 | Recon Loss=0.362847\n",
      "Epoch 10/10 | Recon Loss=0.357585\n",
      "AE training done.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_AE = 10\n",
    "\n",
    "for epoch in range(1, EPOCHS_AE+1):\n",
    "    ae_model.train()\n",
    "    total_loss = 0\n",
    "    for xb, _ in train_loader_ae:\n",
    "        xb = xb.to(DEVICE)\n",
    "        recon = ae_model(xb)\n",
    "        loss = criterion_ae(recon, xb)\n",
    "        optimizer_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(train_loader_ae)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS_AE} | Recon Loss={total_loss:.6f}\")\n",
    "\n",
    "print(\"AE training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8492ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE threshold (95th percentile): 0.8186171\n",
      "üîç Autoencoder Metrics:\n",
      "Accuracy : 0.6183464500296183\n",
      "Precision: 0.8386167146974063\n",
      "Recall   : 0.2559366754617414\n",
      "F1-score : 0.3921832884097035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.618346</td>\n",
       "      <td>0.838617</td>\n",
       "      <td>0.255937</td>\n",
       "      <td>0.392183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy  Precision    Recall        F1\n",
       "0  Autoencoder  0.618346   0.838617  0.255937  0.392183"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_model.eval()\n",
    "\n",
    "# Reconstruction error on train normals (for threshold)\n",
    "with torch.no_grad():\n",
    "    train_errs = []\n",
    "    for xb, _ in train_loader_ae:\n",
    "        xb = xb.to(DEVICE)\n",
    "        recon = ae_model(xb)\n",
    "        err = ((recon - xb)**2).mean(dim=1)\n",
    "        train_errs.extend(err.cpu().numpy())\n",
    "train_errs = np.array(train_errs)\n",
    "threshold = np.percentile(train_errs, 95)  # top 5% as anomalies\n",
    "print(\"AE threshold (95th percentile):\", threshold)\n",
    "\n",
    "# Apply to test set\n",
    "test_ds_ae = WindowDataset(X_test, y_test)\n",
    "test_loader_ae = DataLoader(test_ds_ae, batch_size=256, shuffle=False)\n",
    "\n",
    "y_true_ae = []\n",
    "y_pred_ae = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader_ae:\n",
    "        xb = xb.to(DEVICE)\n",
    "        recon = ae_model(xb)\n",
    "        err = ((recon - xb)**2).mean(dim=1).cpu().numpy()\n",
    "        preds = (err >= threshold).astype(int)  # 1 = attack\n",
    "        y_true_ae.extend(yb.numpy().tolist())\n",
    "        y_pred_ae.extend(preds.tolist())\n",
    "\n",
    "acc_ae, prec_ae, rec_ae, f1_ae = compute_metrics(y_true_ae, y_pred_ae, \"Autoencoder\")\n",
    "\n",
    "df_ae = pd.DataFrame([[ \"Autoencoder\", acc_ae, prec_ae, rec_ae, f1_ae ]],\n",
    "                     columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_ae.to_csv(\"results/Autoencoder.csv\", index=False)\n",
    "df_ae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f8f6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå≤ Training Random Forest...\n",
      "üîç RandomForest Metrics:\n",
      "Accuracy : 0.51992891596852\n",
      "Precision: 1.0\n",
      "Recall   : 0.0021108179419525065\n",
      "F1-score : 0.00421274354923644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.519929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy  Precision    Recall        F1\n",
       "0  RandomForest  0.519929        1.0  0.002111  0.004213"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"\\nüå≤ Training Random Forest...\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=25,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "acc_rf, prec_rf, rec_rf, f1_rf = compute_metrics(y_test, y_pred_rf, \"RandomForest\")\n",
    "\n",
    "df_rf = pd.DataFrame([[ \"RandomForest\", acc_rf, prec_rf, rec_rf, f1_rf ]],\n",
    "                     columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "df_rf.to_csv(\"results/RandomForest.csv\", index=False)\n",
    "df_rf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
